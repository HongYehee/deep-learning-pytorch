{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fad551-2a80-4c07-ba4f-141439995449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "if USE_CUDA :\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf181af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d291402",
   "metadata": {},
   "source": [
    "- 특징 추출 부분(초기 Conv 레이어들)을 동결하고, 출력층(FC Layer)만 재학습\n",
    "- AdaptiveAvgPool2d\n",
    "1)텐서의 공간 차원(Height, Width)을 평균 연산으로 고정된 크기로 변환.\n",
    "2) 공간 정보를 축소하거나, CNN 출력 크기를 Fully Connected Layer 입력으로 변환하기 전에 사용.\n",
    "3) 예: 입력 크기가 (Batch, Channels, Height, Width)일 때 Height와 Width를 원하는 고정 값으로 줄임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e2799",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\ilhan/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a0294b67324d1d854cee0323f8ea41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resnet = models.vgg16(pretrained=True)\n",
    "resnet = models.resnet152(pretrained=True)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01a8afc-113a-486b-b0df-7481d48aa372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터를 텐서 객체로 변환하기 위한 객체를 생성한다.\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "# 이미지 데이터를 64x64사이즈 크기의 텐서 객체로 만들어주는 도구\n",
    "# Compose : 리스트 안에 들어있는 변환기 순서대로 데이터를 통과시켜 만들어준다.\n",
    "# 이미지를 64x64 사이즈로 변환 -> 텐서객체로 생성\n",
    "transform_base = transforms.Compose([transforms.Resize((64, 64)), \n",
    "                                     transforms.ToTensor()])\n",
    "# 학습용 이미지 관리 객체\n",
    "train_dataset = ImageFolder(root='./splitted/train/', transform=transform_base)\n",
    "# 검증용 이미지 관리 객체\n",
    "val_dataset = ImageFolder(root='./splitted/val/', transform=transform_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "044afb52-ab21-4afa-9ace-96d01785f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더를 생성한다.\n",
    "# num_workers : 작업시 멀티코어를 이용하겠다는 의미(4 : 4개의 코어에 나눠서 병렬처리)\n",
    "# 만약 멀티코어가 지원되지 않는 컴퓨터 환경이면 오류가 발생한다. 만약 이렇다면\n",
    "# num_workers를 지워주세요\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c887958-4804-46a6-b332-b3b8fd56f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        super(Net, self).__init__()\n",
    "        # resnet 152 사전학습 모델\n",
    "        # pretrained : True를 넣어주면 1400만장의 이미지를 학습해서 얻은\n",
    "        # Conv 레이어의 커널의 가중치가 설정되어 있는 상태로 받아올 수 있다.\n",
    "        self.resnet = models.resnet152(pretrained=True)\n",
    "        # resnet이 가지고 있는 모든 가중치에 대해 동결시킨다.(학습때 참여하지 않는다)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # for param in self.resnet.layer4.parameters():\n",
    "        #     param.requires_grad = True\n",
    "        # for param in self.resnet.fc.parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "        # for param in self.resnet.layer4[1].parameters():\n",
    "        #     param.requires_grad = True\n",
    "\n",
    "\n",
    "        # resnet 이 전달해 주는 데이터의 개수\n",
    "        cnt = self.resnet.fc.in_features\n",
    "\n",
    "        # resnet의 출력층을 변경해준다.\n",
    "        self.resnet.fc = nn.Linear(in_features=cnt, out_features=33)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.resnet(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e531f3-b6b8-4889-8b83-562c3b262365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 모델 객체 생성한다.\n",
    "model_base = Net().to(DEVICE)\n",
    "# 경사 하강법\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711b3380-8ad4-4228-862b-257ff0803502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "def train(model, train_loader, optimizer) :\n",
    "    model.train()\n",
    "    for data, target in train_loader :\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76607842-35f1-424e-a2ba-b0bf30baa875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가 함수\n",
    "def evaluate(model, test_loader) :\n",
    "    model.eval()\n",
    "    # 오차값을 담을 변수\n",
    "    test_loss = 0\n",
    "    # 얼마나 잘 맞췄지..\n",
    "    correct = 0\n",
    "\n",
    "    # 경사 하강법이 동작하지 않는 부분\n",
    "    with torch.no_grad() :\n",
    "        # 데이터의 수 만큼 반복한다.\n",
    "        for data, target in test_loader :\n",
    "            data = data.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            # 오차를 누적한다.\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            # 맞춘 개수를 누적한다.\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    # 누적한 오차를 데이터의 수 만큼 나줘서 평균 오차를 구한다.\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # 맞춘 개수를 전체 개수로 나눠 맞춘 확률을 구한다.\n",
    "    test_accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5c7a71-2c08-49ea-901e-4587121bab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 학습 하는 함수\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs=30) :\n",
    "    # 학습 중 측정하는 정확도 최대치를 담을 변수\n",
    "    best_acc = 0\n",
    "    # 모델의 성능이 개선되었을 때만 학습모델의 가중치 데이터를 담을 변수\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    # 학습 횟수 만큼 반복한다.\n",
    "    for epoch in range(1, num_epochs + 1) :\n",
    "        # 학습 시작 시간을 담아준다.\n",
    "        since = time.time()\n",
    "        # 학습 함수 호출\n",
    "        train(model, train_loader, optimizer)\n",
    "        # 평가 함수 호출\n",
    "        train_loss, train_acc = evaluate(model, train_loader)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        # 검증용 데이터에 대한 평가수치가 이전에 가장 좋았던 것 보다 더 좋아지면..\n",
    "        if val_acc > best_acc :\n",
    "            # 최고 평가 점수 변수에 덮어 씌워준다.\n",
    "            best_acc = val_acc\n",
    "            # 학습 모델의 가중치 데이터를 덮어씌워준다.\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        \n",
    "        # 현재시간에서 학습 시작시간을 빼서 얼마나 걸렸는지 구한다.\n",
    "        time_elapsed = time.time() - since\n",
    "        print(f'{epoch} 번째 학습')\n",
    "        print(f'학습 데이터 오차 : {train_loss}, 학습 데이터 정확도 : {train_acc}')\n",
    "        print(f'검증 데이터 오차 : {val_loss}, 검증 데이터 정확도 : {val_acc}')\n",
    "        print(f'학습 소요 시간 : {time_elapsed}')\n",
    "        print('--------------')\n",
    "\n",
    "    # 학습이 완료되면 지금까지에서 얻은 최상의 가중치를 학습 모델에 넣어준다.\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543e7735-9d95-4523-91dd-bf320b42ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "# base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, 2)\n",
    "# 학습이 완료된 모델을 저장한다.\n",
    "torch.save(base, 'resnet152.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bae2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "test_dataset = ImageFolder(root='./splitted/test/', transform=transform_base)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "data_iter = iter(test_loader)   # DataLoader의 iterator 생성\n",
    "batch_x, batch_y = next(data_iter)  # 첫 번째 배치 가져오기\n",
    "# 데이터 출력\n",
    "print(\"Feature (x):\", batch_x)       # 입력 데이터\n",
    "print(\"Label (y):\", batch_y)         # 정답 라벨\n",
    "print(\"Feature shape:\", batch_x.shape)  # 배치 크기 확인\n",
    "print(\"Label shape:\", batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db01f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c3cc2-2ca8-4ffd-a106-835f5ba46bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "test_dataset = ImageFolder(root='./splitted/test/', transform=transform_base)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True, num_workers=4)\n",
    "\n",
    "model = torch.load('resnet152.pt')\n",
    "\n",
    "with torch.no_grad() :\n",
    "    result = []\n",
    "    # 데이터의 수 만큼 반복한다.\n",
    "    for data, target in test_loader :\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        # 결과를 예측한다.\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "        result = result + pred.reshape(-1).tolist()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2824e-d2a5-43e5-ac02-98d85f651204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 원래의 이름으로 변경한다.\n",
    "results_data = []\n",
    "# 각 이름별 숫자값을 가지고 있는 딕셔너리를 추출한다.\n",
    "classes_dict = test_dataset.class_to_idx\n",
    "# 이름만 추출한다.\n",
    "classes_names = list(classes_dict.keys())\n",
    "# 예측한 결과의 수 만큼 반복한다.\n",
    "for r1 in result :\n",
    "    # 이름에서 결과번째 이름을 가져온다.\n",
    "    n1 = classes_names[r1]\n",
    "    # 결과에 담아준다.\n",
    "    results_data.append(n1)\n",
    "\n",
    "print(results_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
