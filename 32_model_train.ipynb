{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bf1717",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a9d8dff-6a6e-4456-b684-f5475cef55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b0f3474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# move model to GPU if available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "# batch size, epoch\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fff79f96-b2ce-47de-8d44-8add94159541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image to tensor (64 * 64)\n",
    "transform_base = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor()])\n",
    "\n",
    "train_dataset = ImageFolder(root='./splitted/train/', transform=transform_base)\n",
    "val_dataset = ImageFolder(root='./splitted/val/', transform=transform_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "066a8b4d-3d7b-432e-a6de-1c9728b62dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05d814ef-6074-4747-9fdf-70e4f320084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Net(nn.Module) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(in_features=4096, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=33)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=.25)\n",
    "\n",
    "        # x = x.view(-1, 4096)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da490b0f-6e67-49fd-8e64-f848925d3241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model_base = Net().to(DEVICE)\n",
    "\n",
    "# gradient descent\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8bd46d1-8d69-4de8-9a0c-0d34b6dd8b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training function\n",
    "def train(model, train_loader, optimizer) :\n",
    "    model.train()\n",
    "    \n",
    "    for i, (data, target) in enumerate(train_loader) :\n",
    "        print(f'Train - [{i+1}/{len(data)}]')\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf28987e-8e30-42ec-9aaa-58268a31c63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def evaluate(model, test_loader) :\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # not working gradient descent\n",
    "    with torch.no_grad() :\n",
    "        for i, (data, target) in enumerate(test_loader) :\n",
    "            print(f'Evaluation - [{i+1}/{len(data)}]')\n",
    "            data = data.to(DEVICE)\n",
    "            target = target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    # average of loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # correct probability\n",
    "    test_accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "606bb18b-7472-4920-a8fa-7b669b059512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_baseline func\n",
    "def train_baseline(model, train_loader, val_loader, optimizer, num_epochs=30) :\n",
    "    print('call')\n",
    "    best_acc = 0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        since = time.time()\n",
    "        train(model, train_loader, optimizer)\n",
    "        train_loss, train_acc = evaluate(model, train_loader)\n",
    "        val_loss, val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        if val_acc > best_acc :\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        time_elapsed = time.time() - since\n",
    "\n",
    "        print(f'Train number [{epoch}]')\n",
    "        print(f'[Train] - Loss  {train_loss} | Accuracy: {train_acc}')\n",
    "        print(f'[Validation] - Loss  {val_loss} | Validation: {val_acc}')\n",
    "        print(f'Train Time: {time_elapsed}')\n",
    "        print('--------------')\n",
    "\n",
    "    # after training, best weight model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d6435-7ee6-411b-9557-3eef45ad435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call\n",
      "Train - [1/256]\n",
      "Train - [2/256]\n",
      "Train - [3/256]\n",
      "Train - [4/256]\n",
      "Train - [5/256]\n",
      "Train - [6/256]\n",
      "Train - [7/256]\n",
      "Train - [8/256]\n",
      "Train - [9/256]\n",
      "Train - [10/256]\n",
      "Train - [11/256]\n",
      "Train - [12/256]\n",
      "Train - [13/256]\n",
      "Train - [14/256]\n",
      "Train - [15/256]\n",
      "Train - [16/256]\n",
      "Train - [17/256]\n",
      "Train - [18/256]\n",
      "Train - [19/256]\n",
      "Train - [20/256]\n",
      "Train - [21/256]\n",
      "Train - [22/256]\n",
      "Train - [23/256]\n",
      "Train - [24/256]\n",
      "Train - [25/256]\n",
      "Train - [26/256]\n",
      "Train - [27/256]\n",
      "Train - [28/256]\n",
      "Train - [29/256]\n",
      "Train - [30/256]\n",
      "Train - [31/256]\n",
      "Train - [32/256]\n",
      "Train - [33/256]\n",
      "Train - [34/256]\n",
      "Train - [35/256]\n",
      "Train - [36/256]\n",
      "Train - [37/256]\n",
      "Train - [38/256]\n",
      "Train - [39/256]\n",
      "Train - [40/256]\n",
      "Train - [41/256]\n",
      "Train - [42/256]\n",
      "Train - [43/256]\n",
      "Train - [44/256]\n",
      "Train - [45/256]\n",
      "Train - [46/256]\n",
      "Train - [47/256]\n",
      "Train - [48/256]\n",
      "Train - [49/256]\n",
      "Train - [50/256]\n",
      "Train - [51/256]\n",
      "Train - [52/256]\n",
      "Train - [53/256]\n",
      "Train - [54/256]\n",
      "Train - [55/256]\n",
      "Train - [56/256]\n",
      "Train - [57/256]\n",
      "Train - [58/256]\n",
      "Train - [59/256]\n",
      "Train - [60/256]\n",
      "Train - [61/256]\n",
      "Train - [62/256]\n",
      "Train - [63/256]\n",
      "Train - [64/256]\n",
      "Train - [65/256]\n",
      "Train - [66/256]\n",
      "Train - [67/256]\n",
      "Train - [68/256]\n",
      "Train - [69/256]\n",
      "Train - [70/256]\n",
      "Train - [71/256]\n",
      "Train - [72/256]\n",
      "Train - [73/256]\n",
      "Train - [74/256]\n",
      "Train - [75/256]\n",
      "Train - [76/256]\n",
      "Train - [77/256]\n",
      "Train - [78/256]\n",
      "Train - [79/256]\n",
      "Train - [80/41]\n",
      "Evaluation - [1/256]\n",
      "Evaluation - [2/256]\n",
      "Evaluation - [3/256]\n",
      "Evaluation - [4/256]\n",
      "Evaluation - [5/256]\n",
      "Evaluation - [6/256]\n",
      "Evaluation - [7/256]\n",
      "Evaluation - [8/256]\n",
      "Evaluation - [9/256]\n",
      "Evaluation - [10/256]\n",
      "Evaluation - [11/256]\n",
      "Evaluation - [12/256]\n",
      "Evaluation - [13/256]\n",
      "Evaluation - [14/256]\n",
      "Evaluation - [15/256]\n",
      "Evaluation - [16/256]\n",
      "Evaluation - [17/256]\n",
      "Evaluation - [18/256]\n",
      "Evaluation - [19/256]\n",
      "Evaluation - [20/256]\n",
      "Evaluation - [21/256]\n",
      "Evaluation - [22/256]\n",
      "Evaluation - [23/256]\n",
      "Evaluation - [24/256]\n",
      "Evaluation - [25/256]\n",
      "Evaluation - [26/256]\n",
      "Evaluation - [27/256]\n",
      "Evaluation - [28/256]\n",
      "Evaluation - [29/256]\n",
      "Evaluation - [30/256]\n",
      "Evaluation - [31/256]\n",
      "Evaluation - [32/256]\n",
      "Evaluation - [33/256]\n",
      "Evaluation - [34/256]\n",
      "Evaluation - [35/256]\n",
      "Evaluation - [36/256]\n",
      "Evaluation - [37/256]\n",
      "Evaluation - [38/256]\n",
      "Evaluation - [39/256]\n",
      "Evaluation - [40/256]\n",
      "Evaluation - [41/256]\n",
      "Evaluation - [42/256]\n",
      "Evaluation - [43/256]\n",
      "Evaluation - [44/256]\n",
      "Evaluation - [45/256]\n",
      "Evaluation - [46/256]\n",
      "Evaluation - [47/256]\n",
      "Evaluation - [48/256]\n",
      "Evaluation - [49/256]\n",
      "Evaluation - [50/256]\n",
      "Evaluation - [51/256]\n",
      "Evaluation - [52/256]\n",
      "Evaluation - [53/256]\n",
      "Evaluation - [54/256]\n",
      "Evaluation - [55/256]\n",
      "Evaluation - [56/256]\n",
      "Evaluation - [57/256]\n",
      "Evaluation - [58/256]\n",
      "Evaluation - [59/256]\n",
      "Evaluation - [60/256]\n",
      "Evaluation - [61/256]\n",
      "Evaluation - [62/256]\n",
      "Evaluation - [63/256]\n",
      "Evaluation - [64/256]\n",
      "Evaluation - [65/256]\n",
      "Evaluation - [66/256]\n",
      "Evaluation - [67/256]\n",
      "Evaluation - [68/256]\n",
      "Evaluation - [69/256]\n",
      "Evaluation - [70/256]\n",
      "Evaluation - [71/256]\n",
      "Evaluation - [72/256]\n",
      "Evaluation - [73/256]\n",
      "Evaluation - [74/256]\n",
      "Evaluation - [75/256]\n",
      "Evaluation - [76/256]\n",
      "Evaluation - [77/256]\n",
      "Evaluation - [78/256]\n",
      "Evaluation - [79/256]\n",
      "Evaluation - [80/41]\n",
      "Evaluation - [1/256]\n",
      "Evaluation - [2/256]\n",
      "Evaluation - [3/256]\n",
      "Evaluation - [4/256]\n",
      "Evaluation - [5/256]\n",
      "Evaluation - [6/256]\n",
      "Evaluation - [7/256]\n",
      "Evaluation - [8/256]\n",
      "Evaluation - [9/256]\n",
      "Evaluation - [10/256]\n",
      "Evaluation - [11/256]\n",
      "Evaluation - [12/256]\n",
      "Evaluation - [13/256]\n",
      "Evaluation - [14/256]\n",
      "Evaluation - [15/256]\n",
      "Evaluation - [16/256]\n",
      "Evaluation - [17/256]\n",
      "Evaluation - [18/256]\n",
      "Evaluation - [19/256]\n",
      "Evaluation - [20/256]\n",
      "Evaluation - [21/256]\n",
      "Evaluation - [22/256]\n",
      "Evaluation - [23/256]\n",
      "Evaluation - [24/256]\n",
      "Evaluation - [25/256]\n",
      "Evaluation - [26/164]\n",
      "Train number [1]\n",
      "[Train] - Loss  1.9182096558972521 | Accuracy: 43.005181347150256\n",
      "[Validation] - Loss  1.939871477107316 | Validation: 43.57099329677026\n",
      "Train Time: 69.58021235466003\n",
      "--------------\n",
      "Train - [1/256]\n",
      "Train - [2/256]\n",
      "Train - [3/256]\n",
      "Train - [4/256]\n",
      "Train - [5/256]\n",
      "Train - [6/256]\n",
      "Train - [7/256]\n",
      "Train - [8/256]\n",
      "Train - [9/256]\n",
      "Train - [10/256]\n",
      "Train - [11/256]\n",
      "Train - [12/256]\n",
      "Train - [13/256]\n",
      "Train - [14/256]\n",
      "Train - [15/256]\n",
      "Train - [16/256]\n",
      "Train - [17/256]\n",
      "Train - [18/256]\n",
      "Train - [19/256]\n",
      "Train - [20/256]\n",
      "Train - [21/256]\n",
      "Train - [22/256]\n",
      "Train - [23/256]\n",
      "Train - [24/256]\n",
      "Train - [25/256]\n",
      "Train - [26/256]\n",
      "Train - [27/256]\n",
      "Train - [28/256]\n",
      "Train - [29/256]\n",
      "Train - [30/256]\n",
      "Train - [31/256]\n",
      "Train - [32/256]\n",
      "Train - [33/256]\n",
      "Train - [34/256]\n",
      "Train - [35/256]\n",
      "Train - [36/256]\n",
      "Train - [37/256]\n",
      "Train - [38/256]\n",
      "Train - [39/256]\n",
      "Train - [40/256]\n",
      "Train - [41/256]\n",
      "Train - [42/256]\n",
      "Train - [43/256]\n",
      "Train - [44/256]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "# base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH)\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, 2)\n",
    "torch.save(base, 'baseline.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "test_dataset = ImageFolder(root='./splitted/test/', transform=transform_base)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "data_iter = iter(test_loader)\n",
    "batch_x, batch_y = next(data_iter)\n",
    "\n",
    "print(\"Feature (x):\", batch_x)\n",
    "print(\"Label (y):\", batch_y)\n",
    "print(\"Feature shape:\", batch_x.shape)\n",
    "print(\"Label shape:\", batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27455b-e64d-4931-bb40-577790504a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "test_dataset = ImageFolder(root='./splitted/test/', transform=transform_base)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "model = torch.load('baseline.pt')\n",
    "\n",
    "with torch.no_grad() :\n",
    "    result = []\n",
    "\n",
    "    for data, target in test_loader :\n",
    "        data = data.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        pred = pred.cpu().numpy()\n",
    "        result = result + pred.reshape(-1).tolist()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f3e86-0a67-434f-9286-cb849125f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_data = []\n",
    "classes_dict = test_dataset.class_to_idx\n",
    "classes_names = list(classes_dict.keys())\n",
    "\n",
    "for r1 in result :\n",
    "    n1 = classes_names[r1]\n",
    "    results_data.append(n1)\n",
    "\n",
    "print(results_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
